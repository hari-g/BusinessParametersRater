/* BusinessImproverJob.java
 * Business Analyzer cloud Final Project
 * Hari Krishna Gajarla and Venkat
 * Group 19
 */


// import org.apache.commons.logging.Log;
// import org.apache.commons.logging.LogFactory;
//import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapred.lib.ChainMapper;
import org.apache.hadoop.mapred.lib.ChainReducer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.mapred.JobConf;



/**
 *
 * @author hari
 */
public class BusinessImproverJob {
    // The Karmasphere Studio Workflow Log displays logging from Apache Commons Logging, for example:
    // private static final Log LOG = LogFactory.getLog("org.smaple.HomeworkJob");

    public static void main(String[] args) throws Exception {
    	System.out.println(System.getProperty("hadoop.tmp.dir"));
    	System.setProperty("hadoop.tmp.dir", "/home/hari/tmp");
        Job job = new Job();

        /* Autogenerated initialization. */
        initJob(job);

        /* Custom initialization. */
        //initCustom(job);

        /* Tell Task Tracker this is the main */
        job.setJarByClass(BusinessImproverJob.class);

        /* This is an example of how to set input and output. */
        FileInputFormat.setInputPaths(job, args[0]);
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        /* You can now do any other job customization. */
        // job.setXxx(...);
        
      //ChainMapper.addMapper(conf, lda, inputKeyClass, inputValueClass, outputKeyClass, outputValueClass, byValue, mapperConf);

        

        //ChainReducer.setReducer(job.getConfiguration(), BusinessImproverMapper.class, Text.class, Text.class, Text.class, Text.class, true, ldareduce.);

        /* And finally, we submit the job. */
        job.submit();

        job.waitForCompletion(true);
        
        Job ldareduce = new  Job();
        initCustom(ldareduce);
        String new_path = args[1]+"//part-r-00000";
        FileInputFormat.setInputPaths(ldareduce, new_path);
        FileOutputFormat.setOutputPath(ldareduce, new Path(args[2]));
        ldareduce.submit();

        ldareduce.waitForCompletion(true); 
        
        
        /*
        Job ratingcalc = new  Job();
        initCustom2(ratingcalc);
        String path_new = args[1]+"//part-r-00000";
        FileInputFormat.setInputPaths(ratingcalc, path_new);
        FileOutputFormat.setOutputPath(ratingcalc, new Path(args[3]));
        ratingcalc.submit();

        ratingcalc.waitForCompletion(true); */
        
       
    }

    /**
     * This method is executed by the workflow
     */
    public static void initCustom(Job job) {
        // Add custom initialisation here, you may have to rebuild your project before
        // changes are reflected in the workflow.
    	
    	// CG_INPUT_HIDDEN
    	job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat.class);

    	// CG_MAPPER_HIDDEN
    	job.setMapperClass(LdaMapper.class);
    	job.getConfiguration().set("mapred.mapper.new-api", "true");

    	// CG_MAPPER
    	job.getConfiguration().set("mapred.map.tasks", "3");
    	job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
    	job.setMapOutputValueClass(org.apache.hadoop.io.Text.class);

    	// CG_PARTITIONER_HIDDEN
    	job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

    	// CG_PARTITIONER

    	// CG_COMPARATOR_HIDDEN

    	// CG_COMPARATOR

    	// CG_COMBINER_HIDDEN

    	// CG_REDUCER_HIDDEN
    	job.setReducerClass(LdaReducer.class);
    	job.getConfiguration().set("mapred.reducer.new-api", "true");

    	// CG_REDUCER
    	job.getConfiguration().set("mapred.reduce.tasks", "2");
    	job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
    	job.setOutputValueClass(org.apache.hadoop.io.Text.class);

    	// CG_OUTPUT_HIDDEN
    	job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

    	// CG_OUTPUT

    	// Others
    	job.getConfiguration().set("", "");
    	
    }
    
    public static void initCustom2(Job job) {
        // Add custom initialisation here, you may have to rebuild your project before
        // changes are reflected in the workflow.
    	
    	// CG_INPUT_HIDDEN
    	job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat.class);

    	// CG_MAPPER_HIDDEN
    	job.setMapperClass(RatingCalculatorMapper.class);
    	job.getConfiguration().set("mapred.mapper.new-api", "true");

    	// CG_MAPPER
    	job.getConfiguration().set("mapred.map.tasks", "3");
    	job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
    	job.setMapOutputValueClass(org.apache.hadoop.io.Text.class);

    	// CG_PARTITIONER_HIDDEN
    	job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

    	// CG_PARTITIONER

    	// CG_COMPARATOR_HIDDEN

    	// CG_COMPARATOR

    	// CG_COMBINER_HIDDEN

    	// CG_REDUCER_HIDDEN
    	job.setReducerClass(RatingCalculatorReducer.class);
    	job.getConfiguration().set("mapred.reducer.new-api", "true");

    	// CG_REDUCER
    	job.getConfiguration().set("mapred.reduce.tasks", "2");
    	job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
    	job.setOutputValueClass(org.apache.hadoop.io.Text.class);

    	// CG_OUTPUT_HIDDEN
    	job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

    	// CG_OUTPUT

    	// Others
    	job.getConfiguration().set("", "");
    	
    }

    /** This method is called from within the constructor to
     * initialize the job.
     * WARNING: Do NOT modify this code. The content of this method is
     * always regenerated by the Job Editor.
     */
    @SuppressWarnings("unchecked")
    // <editor-fold defaultstate="collapsed" desc="Generated Code">//GEN-BEGIN:initJob
    public static void initJob(Job job) {
org.apache.hadoop.conf.Configuration conf = job.getConfiguration();
// Generating code using Karmasphere Protocol for Hadoop 0.20
// CG_GLOBAL

// CG_INPUT_HIDDEN
job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat.class);

// CG_MAPPER_HIDDEN
job.setMapperClass(BusinessImproverMapper.class);
job.getConfiguration().set("mapred.mapper.new-api", "true");

// CG_MAPPER
job.getConfiguration().set("mapred.map.tasks", "3");
job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
job.setMapOutputValueClass(org.apache.hadoop.io.Text.class);

// CG_PARTITIONER_HIDDEN
job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

// CG_PARTITIONER

// CG_COMPARATOR_HIDDEN

// CG_COMPARATOR

// CG_COMBINER_HIDDEN

// CG_REDUCER_HIDDEN
job.setReducerClass(BusinessImproverReducer.class);
job.getConfiguration().set("mapred.reducer.new-api", "true");

// CG_REDUCER
job.getConfiguration().set("mapred.reduce.tasks", "2");
job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
job.setOutputValueClass(org.apache.hadoop.io.Text.class);

// CG_OUTPUT_HIDDEN
job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

// CG_OUTPUT

// Others
job.getConfiguration().set("", "");
}











    // </editor-fold>//GEN-END:initJob

}
